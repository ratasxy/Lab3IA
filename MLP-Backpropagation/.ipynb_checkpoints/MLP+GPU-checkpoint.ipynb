{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.7.0\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.1.3\n",
      "Scikit-Learn 0.23.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# What version of Python do you have?\n",
    "import torch\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    media_vector = vector.mean(axis=0)\n",
    "    std_vector = vector.std(axis=0)\n",
    "    return (vector - media_vector)/std_vector, media_vector, std_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implemento la función sigmoidal\n",
    "def sigma(x):\n",
    "    return 1.0 / (1 + torch.exp(-x)) \n",
    "\n",
    "\n",
    "A = torch.tensor([[1.,0.],[0.,1.]]).to('cuda')\n",
    "b = torch.tensor([[0.],[0.]]).to('cuda')\n",
    "ans = torch.matmul(A,b)\n",
    "sigma(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular Función de Costo\n",
    "En teoría la función costo es la norma del vector resultante de la diferencia del valor resultante de la entrada X y su valor resultante definido.  \n",
    "$$\n",
    "Cost(X, y) = \\sum_{i=0}^{m}(y^i- \\hat{y}^i)^{2} = \\|h_{\\theta}(X) - y\\|\n",
    "$$\n",
    "En el caso de nuestra implementación como todos los datos de entrada serán insertados en una sola pasada, necesito el promedio de la diferencia de cada valor de salida.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7071, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recibo los datos\n",
    "def Calcular_Funcion_Costo(y):\n",
    "    return torch.linalg.norm(y)\n",
    "    #return torch.linalg.norm(y) / y.nelement()\n",
    "    #return torch.sqrt(torch.sum(y**2)) / y.nelement()\n",
    "    #return torch.mean(torch.linalg.norm(vector, dim=0))\n",
    "A = torch.tensor([[1.,0.],[0.,1.]]).to('cuda')\n",
    "b = torch.tensor([[0.],[0.]]).to('cuda')\n",
    "ans = torch.matmul(A,b)\n",
    "Calcular_Funcion_Costo(sigma(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dS\n",
    "Recibe los datos $D$ y calcula para dichos datos la derivada de la función sigmoidal.  \n",
    "Recibiré un vector $a$ como en la teoría está establecido, luego retornaré la derivada de la función sigmoidal, dada por la ecuación:  \n",
    "$$\n",
    "\\frac{d\\sigma(x)}{dx} = \\sigma(x)(1 - \\sigma(x))\n",
    "$$\n",
    "Todo esto en notación vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1966],\n",
      "        [0.1050]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def dS(D):\n",
    "    # recordemos que la variable sigma es la función sigmoidal vectorizada\n",
    "    return sigma(D)*(1 - sigma(D))\n",
    "\n",
    "a = torch.tensor([[1.],[2.]]).to('cuda')\n",
    "print(dS(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward\n",
    "Recibe los datos $X$ y un diccionario de parámetros $W$ (i.e. los pesos de cada capa), donde cada elemento del diccionario es una matriz de pesos; y realiza la etapa de propagación. Devuelve un diccionario de activaciones $A$, donde cada elemento del diccionario son las activaciones de cada capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'W': tensor([[ 1.0610, -0.3707, -0.4381],\n",
      "        [-1.3938, -0.9740,  0.3350]], device='cuda:0', dtype=torch.float64), 'b': tensor([[-0.5897],\n",
      "        [-0.6444]], device='cuda:0', dtype=torch.float64)}, 1: {'W': tensor([[ 0.5771, -0.7015],\n",
      "        [ 0.4396, -0.6355],\n",
      "        [ 0.5541,  0.9023]], device='cuda:0', dtype=torch.float64), 'b': tensor([[0.5018],\n",
      "        [0.2165],\n",
      "        [0.1532]], device='cuda:0', dtype=torch.float64)}}\n",
      "{0: {'a': tensor([[100.,  10.],\n",
      "        [ 50.,  70.],\n",
      "        [ 74.,  20.]], device='cuda:0', dtype=torch.float64), 'z': tensor([[100.,  10.],\n",
      "        [ 50.,  70.],\n",
      "        [ 74.,  20.]], device='cuda:0', dtype=torch.float64)}, 1: {'a': tensor([[1.0000e+00, 1.8913e-11],\n",
      "        [6.4034e-72, 9.2453e-34]], device='cuda:0', dtype=torch.float64), 'z': tensor([[  54.5629,  -24.6912],\n",
      "        [-163.9293,  -76.0638]], device='cuda:0', dtype=torch.float64)}, 2: {'a': tensor([[0.7463, 0.6229],\n",
      "        [0.6584, 0.5539],\n",
      "        [0.6698, 0.5382]], device='cuda:0', dtype=torch.float64), 'z': tensor([[1.0788, 0.5018],\n",
      "        [0.6561, 0.2165],\n",
      "        [0.7073, 0.1532]], device='cuda:0', dtype=torch.float64)}}\n"
     ]
    }
   ],
   "source": [
    "# El primer paso es crear todas las matrices de pesos basándonos en las dimensiones de la entrada X\n",
    "# y el tamaño del batch que ingresaremos\n",
    "def generar_pesos(parameters):\n",
    "    layers = {}\n",
    "    n = len(parameters)\n",
    "    # i -> (0,1,...,n-1)\n",
    "    for i in range(0, n-1):\n",
    "        layers[i] = {\"W\": torch.randn(parameters[i+1], parameters[i], dtype=torch.double).to('cuda'),\n",
    "                     \"b\": torch.randn(parameters[i+1], 1, dtype=torch.double).to('cuda')}\n",
    "    return layers\n",
    "\n",
    "def Forward(X, W):\n",
    "    A = {0: {\"a\": X, \"z\": X}} # el diccionario a retornar\n",
    "               # como primer elemento de la lista esta X, para mantener el orden\n",
    "    n = len(W) # primero extraigo la cantidad de pesos para iterar sobre eso\n",
    "    for i in range(1, n + 1):\n",
    "        activation = torch.matmul(W[i-1][\"W\"], A[i-1][\"a\"]) + W[i-1][\"b\"] # se hace broadcasting al sumar el bias\n",
    "        A[i] = {\"a\": sigma(activation), \"z\": activation}\n",
    "    return A\n",
    "\n",
    "\n",
    "Wout = generar_pesos([3,2,3])\n",
    "print(Wout)\n",
    "Xin = torch.tensor([[100, 10],[50, 70],[74, 20]], dtype=torch.double).to('cuda')\n",
    "print(Forward(Xin, Wout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'W': tensor([[-1.4010,  0.8687,  1.1399],\n",
      "        [ 0.7904, -1.9768,  1.4166]], device='cuda:0', dtype=torch.float64), 'b': tensor([[1.0430],\n",
      "        [0.4766]], device='cuda:0', dtype=torch.float64)}, 1: {'W': tensor([[ 0.5027, -0.3178],\n",
      "        [-0.5467, -1.3417],\n",
      "        [ 0.1107,  0.3005]], device='cuda:0', dtype=torch.float64), 'b': tensor([[-0.5026],\n",
      "        [ 1.5596],\n",
      "        [-0.3113]], device='cuda:0', dtype=torch.float64)}}\n",
      "{0: {'W': tensor([[-1.4010,  0.8687,  1.1399],\n",
      "        [ 0.7904, -1.9768,  1.4166]], device='cuda:0', dtype=torch.float64), 'b': tensor([[1.0430],\n",
      "        [0.4766]], device='cuda:0', dtype=torch.float64)}, 1: {'W': tensor([[ 0.4402, -0.2441],\n",
      "        [-0.5207, -1.4101],\n",
      "        [ 0.0550,  0.2383]], device='cuda:0', dtype=torch.float64), 'b': tensor([[-0.4970],\n",
      "        [ 1.5384],\n",
      "        [-0.3703]], device='cuda:0', dtype=torch.float64)}}\n"
     ]
    }
   ],
   "source": [
    "def Backward(X, A, W, y, lr):\n",
    "    \"\"\"\n",
    "    X: valores de entrada\n",
    "    A: diccionario con los resultados de cada capa\n",
    "    W: diccionario con los pesos de cada capa\n",
    "    y: salida de la última capa\n",
    "    lr: tasa de aprendizaje (learning rate en inglés)\n",
    "    \"\"\"\n",
    "    r = len(A)-1\n",
    "    deltas = {r: -(y - A[r][\"a\"]) * dS(A[r][\"z\"])}\n",
    "    for i in range(r-1,-1,-1):\n",
    "        deltas[i] = torch.matmul(torch.t(W[i][\"W\"]), deltas[i+1]) * dS(A[i][\"z\"])\n",
    "        # ahora viene la etapa del gradiente descendiente, para los pesos\n",
    "        W[i][\"W\"] = W[i][\"W\"] - lr * torch.matmul(deltas[i+1], torch.t(A[i][\"a\"]))\n",
    "        W[i][\"b\"] = W[i][\"b\"] - lr * deltas[i+1]\n",
    "        W[i][\"b\"] = torch.mean(W[i][\"b\"], dim=1, keepdim=True)\n",
    "    return W\n",
    "\n",
    "Wout = generar_pesos([3,2,3])\n",
    "print(Wout)\n",
    "Xin = torch.tensor([[100, 10],[50, 70],[74, 20]], dtype=torch.double).to('cuda')\n",
    "A = Forward(Xin, Wout)\n",
    "yout = torch.tensor([[1, 0],[0, 1],[0, 0]], dtype=torch.double).to('cuda')\n",
    "print(Backward(Xin, A, Wout, yout, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente Descendiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.,  10.],\n",
      "        [ 50., 100.],\n",
      "        [ 74., 200.]], device='cuda:0', dtype=torch.float64)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.]], device='cuda:0', dtype=torch.float64)\n",
      "tensor([[0.9565, 0.0477],\n",
      "        [0.0448, 0.9507],\n",
      "        [0.0125, 0.0120]], device='cuda:0', dtype=torch.float64)\n",
      "{0: {'W': tensor([[ 1.0870,  0.1922,  2.1272],\n",
      "        [-0.0183, -0.0778,  0.6326],\n",
      "        [-0.7345, -1.4435, -0.0217],\n",
      "        [ 0.8280,  0.8204, -0.6601]], device='cuda:0', dtype=torch.float64), 'b': tensor([[ 2.2541],\n",
      "        [ 0.1484],\n",
      "        [-0.0714],\n",
      "        [-0.8803]], device='cuda:0', dtype=torch.float64)}, 1: {'W': tensor([[-0.7086, -2.7267, -0.1962,  6.0847],\n",
      "        [-0.6228,  2.2853,  0.9127, -6.0189],\n",
      "        [-1.9426, -2.5066,  1.3835,  0.0470]], device='cuda:0',\n",
      "       dtype=torch.float64), 'b': tensor([[0.4419],\n",
      "        [1.2977],\n",
      "        [0.0361]], device='cuda:0', dtype=torch.float64)}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.0945, device='cuda:0', dtype=torch.float64),\n",
       " tensor(0.0944, device='cuda:0', dtype=torch.float64),\n",
       " tensor(0.0944, device='cuda:0', dtype=torch.float64)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Gradiente_Descendiente(X, y, W, epochs, lr):\n",
    "    result = {\"costs\": []}\n",
    "    Wout = copy.deepcopy(W)\n",
    "    for i in range(epochs):\n",
    "        Aout = Forward(X, Wout)\n",
    "        #result[\"weigths\"].append(W)\n",
    "        result[\"costs\"].append(Calcular_Funcion_Costo(y - Aout[len(Aout)-1][\"a\"]))\n",
    "        Backward(X, Aout, Wout, y, lr)\n",
    "    \n",
    "    #for idx in Wout:\n",
    "        #Wout[idx]['b'] = Wout[idx]['b'][:,0:1]\n",
    "    result['W'] = Wout\n",
    "    return result\n",
    "\n",
    "Wout = generar_pesos([3,4,3])\n",
    "Xin = torch.tensor([[100, 10],[50, 100],[74, 200]], dtype=torch.double).to('cuda')\n",
    "yout = torch.tensor([[1, 0],[0, 1],[0, 0]], dtype=torch.double).to('cuda')\n",
    "\n",
    "ans = Gradiente_Descendiente(Xin, yout, Wout, 2000, 0.3)\n",
    "print(Xin)\n",
    "print(yout)\n",
    "print(Forward(Xin, ans['W'])[2][\"a\"])\n",
    "print(ans['W'])\n",
    "ans[\"costs\"][-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimaremos el resultado de nuestros vectores considerando la posición del vector \n",
    "#con la máxima puntuación como 1 y el resto como 0, p.ej.\n",
    "# si tueviésemos un vector a = [0.5, 0.2, 0.7], su estimado será [0, 0, 1]\n",
    "def estimate_result(x): # receives a vector of n*1\n",
    "    Xout = torch.zeros(x.shape[0], x.shape[1], dtype=torch.int).to('cuda')\n",
    "    maxidx = torch.argmax(x, dim=0)\n",
    "    for i in range(maxidx.shape[0]):\n",
    "        Xout[maxidx[i], i] = 1\n",
    "    return Xout\n",
    "\n",
    "# una pequeña prueba\n",
    "vectest = torch.tensor([[0.5],[0.2],[0.7]], dtype=torch.double).to('cuda')\n",
    "vectest = estimate_result(vectest)\n",
    "vectest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Calcular_Accuracy(YMLP, Y):\n",
    "    set_size = YMLP.shape[1]\n",
    "    correct = 0.0\n",
    "    for i in range(set_size):\n",
    "        if torch.all(torch.eq(YMLP[:,i], Y[:,i])):\n",
    "            correct += 1.0\n",
    "    return correct / set_size\n",
    "\n",
    "YMLP = torch.tensor([[1,0],[0,0],[0,1]], dtype=torch.double).to('cuda')\n",
    "Y = torch.tensor([[1,0],[1,0],[0,1]], dtype=torch.double).to('cuda')\n",
    "Calcular_Accuracy(YMLP, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myset será una lista con los valores de los \n",
    "def KfoldsCrossValidation(X, y, Y, params, k=3, shuff=True):\n",
    "    \"\"\"\n",
    "    X: el conjunto de datos reescalados\n",
    "    y: la columna de datos categóricos\n",
    "    Y: la columna de los datos categóricos con la configuración one hot\n",
    "    params: un diccionario de datos con los siguiente parámetros\n",
    "            -layers: una lista con el número de neuronas por cada capa\n",
    "            -learning: una lista con las tasas de aprendizaje a evaluar\n",
    "            -epochs: una lista con el número de épocas(iteraciones)\n",
    "    k: el k para realizar el k-folds (3 por defecto)\n",
    "    shuff: la variable booleana para decidir si los datos se barajan o no\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuff)\n",
    "    learning_rates = params['learning']\n",
    "    epochs = params['epochs']\n",
    "    layers = params['layers']\n",
    "    bestAcc = 0\n",
    "    bestLr = -1\n",
    "    bestEpoch = -1\n",
    "    Weights = generar_pesos(layers)\n",
    "    for lr in learning_rates:\n",
    "        for epoch in epochs:\n",
    "            print(f'Tasa de aprendizaje: {lr}, épocas: {epoch} ', end=\"\")\n",
    "            avgAcc = 0\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                #print(\"TRAIN:\", train_index[0:10], \"TEST:\", test_index[0:10])\n",
    "                X_train, X_test = torch.from_numpy(np.array(X[train_index], dtype='double').T).to('cuda'), torch.from_numpy(np.array(X[test_index], dtype='double').T).to('cuda')\n",
    "                y_train, y_test = torch.from_numpy(np.array(Y[train_index], dtype='double').T).to('cuda'), torch.from_numpy(np.array(Y[test_index], dtype='int').T).to('cuda')\n",
    "                ans = Gradiente_Descendiente(X_train, y_train, Weights, epoch, lr)\n",
    "                acc = estimate_result(Forward(X_test, ans['W'])[len(layers)-1][\"a\"]) # primero estimamos el valor de la última capa\n",
    "                acc = Calcular_Accuracy(acc, y_test)\n",
    "                avgAcc += acc\n",
    "            avgAcc /= k\n",
    "            if avgAcc > bestAcc:\n",
    "                bestAcc = avgAcc\n",
    "                bestLr = lr\n",
    "                bestEpoch = epoch\n",
    "            print(f'Average acc: {avgAcc}')\n",
    "            \n",
    "                \n",
    "    print(f'Results\\nBest learning rate: {bestLr}')\n",
    "    print(f'Best Nro epochs: {bestEpoch}')\n",
    "    print(f'Best Average Accuracy: {bestAcc}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación del género de música"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music genres:\n",
      " classical    100\n",
      "disco        100\n",
      "reggae       100\n",
      "hiphop       100\n",
      "rock         100\n",
      "blues        100\n",
      "country      100\n",
      "pop          100\n",
      "jazz         100\n",
      "metal        100\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>beats</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>50</td>\n",
       "      <td>0.380260</td>\n",
       "      <td>0.248262</td>\n",
       "      <td>2116.942959</td>\n",
       "      <td>1956.611056</td>\n",
       "      <td>4196.107960</td>\n",
       "      <td>0.127272</td>\n",
       "      <td>-26.929785</td>\n",
       "      <td>107.334008</td>\n",
       "      <td>...</td>\n",
       "      <td>14.336612</td>\n",
       "      <td>-13.821769</td>\n",
       "      <td>7.562789</td>\n",
       "      <td>-6.181372</td>\n",
       "      <td>0.330165</td>\n",
       "      <td>-6.829571</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>-7.570825</td>\n",
       "      <td>2.918987</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.703125</td>\n",
       "      <td>44</td>\n",
       "      <td>0.306451</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>1156.070496</td>\n",
       "      <td>1497.668176</td>\n",
       "      <td>2170.053545</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>-233.860772</td>\n",
       "      <td>136.170239</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.250578</td>\n",
       "      <td>3.959198</td>\n",
       "      <td>5.322555</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>-1.107202</td>\n",
       "      <td>-4.556555</td>\n",
       "      <td>-2.436490</td>\n",
       "      <td>3.316913</td>\n",
       "      <td>-0.608485</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.999081</td>\n",
       "      <td>75</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>0.151571</td>\n",
       "      <td>1331.073970</td>\n",
       "      <td>1973.643437</td>\n",
       "      <td>2900.174130</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>-221.802549</td>\n",
       "      <td>110.843070</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.037723</td>\n",
       "      <td>-12.652228</td>\n",
       "      <td>-1.821905</td>\n",
       "      <td>-7.260097</td>\n",
       "      <td>-6.660252</td>\n",
       "      <td>-14.682694</td>\n",
       "      <td>-11.719264</td>\n",
       "      <td>-11.025216</td>\n",
       "      <td>-13.387260</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.570312</td>\n",
       "      <td>91</td>\n",
       "      <td>0.269320</td>\n",
       "      <td>0.119072</td>\n",
       "      <td>1361.045467</td>\n",
       "      <td>1567.804596</td>\n",
       "      <td>2739.625101</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>-207.208080</td>\n",
       "      <td>132.799175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613248</td>\n",
       "      <td>0.384877</td>\n",
       "      <td>2.605128</td>\n",
       "      <td>-5.188924</td>\n",
       "      <td>-9.527455</td>\n",
       "      <td>-9.244394</td>\n",
       "      <td>-2.848274</td>\n",
       "      <td>-1.418707</td>\n",
       "      <td>-5.932607</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.499023</td>\n",
       "      <td>74</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.137728</td>\n",
       "      <td>1811.076084</td>\n",
       "      <td>2052.332563</td>\n",
       "      <td>3927.809582</td>\n",
       "      <td>0.075480</td>\n",
       "      <td>-145.434568</td>\n",
       "      <td>102.829023</td>\n",
       "      <td>...</td>\n",
       "      <td>7.457218</td>\n",
       "      <td>-10.470444</td>\n",
       "      <td>-2.360483</td>\n",
       "      <td>-6.783623</td>\n",
       "      <td>2.671134</td>\n",
       "      <td>-4.760879</td>\n",
       "      <td>-0.949005</td>\n",
       "      <td>0.024832</td>\n",
       "      <td>-2.005315</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tempo  beats  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  103.359375     50     0.380260  0.248262        2116.942959   \n",
       "1   95.703125     44     0.306451  0.113475        1156.070496   \n",
       "2  151.999081     75     0.253487  0.151571        1331.073970   \n",
       "3  184.570312     91     0.269320  0.119072        1361.045467   \n",
       "4  161.499023     74     0.391059  0.137728        1811.076084   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         1956.611056  4196.107960            0.127272  -26.929785   \n",
       "1         1497.668176  2170.053545            0.058613 -233.860772   \n",
       "2         1973.643437  2900.174130            0.042967 -221.802549   \n",
       "3         1567.804596  2739.625101            0.069124 -207.208080   \n",
       "4         2052.332563  3927.809582            0.075480 -145.434568   \n",
       "\n",
       "        mfcc2  ...     mfcc12     mfcc13    mfcc14    mfcc15    mfcc16  \\\n",
       "0  107.334008  ...  14.336612 -13.821769  7.562789 -6.181372  0.330165   \n",
       "1  136.170239  ...  -2.250578   3.959198  5.322555  0.812028 -1.107202   \n",
       "2  110.843070  ... -13.037723 -12.652228 -1.821905 -7.260097 -6.660252   \n",
       "3  132.799175  ...  -0.613248   0.384877  2.605128 -5.188924 -9.527455   \n",
       "4  102.829023  ...   7.457218 -10.470444 -2.360483 -6.783623  2.671134   \n",
       "\n",
       "      mfcc17     mfcc18     mfcc19     mfcc20  label  \n",
       "0  -6.829571   0.965922  -7.570825   2.918987  blues  \n",
       "1  -4.556555  -2.436490   3.316913  -0.608485  blues  \n",
       "2 -14.682694 -11.719264 -11.025216 -13.387260  blues  \n",
       "3  -9.244394  -2.848274  -1.418707  -5.932607  blues  \n",
       "4  -4.760879  -0.949005   0.024832  -2.005315  blues  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leo los datos\n",
    "Data = pd.read_csv('music_genre.csv')\n",
    "Data = Data.drop(['filename'], axis=1)\n",
    "# hacemos un shuffle de los datos\n",
    "# Data = Data.sample(frac=1).reset_index(drop=True)\n",
    "print(\"Music genres:\\n\", Data['label'].value_counts())\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding para los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.get_dummies(Data[['label']])\n",
    "Xinput = Data.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>beats</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>50</td>\n",
       "      <td>0.380260</td>\n",
       "      <td>0.248262</td>\n",
       "      <td>2116.942959</td>\n",
       "      <td>1956.611056</td>\n",
       "      <td>4196.107960</td>\n",
       "      <td>0.127272</td>\n",
       "      <td>-26.929785</td>\n",
       "      <td>107.334008</td>\n",
       "      <td>...</td>\n",
       "      <td>14.336612</td>\n",
       "      <td>-13.821769</td>\n",
       "      <td>7.562789</td>\n",
       "      <td>-6.181372</td>\n",
       "      <td>0.330165</td>\n",
       "      <td>-6.829571</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>-7.570825</td>\n",
       "      <td>2.918987</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.703125</td>\n",
       "      <td>44</td>\n",
       "      <td>0.306451</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>1156.070496</td>\n",
       "      <td>1497.668176</td>\n",
       "      <td>2170.053545</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>-233.860772</td>\n",
       "      <td>136.170239</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.250578</td>\n",
       "      <td>3.959198</td>\n",
       "      <td>5.322555</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>-1.107202</td>\n",
       "      <td>-4.556555</td>\n",
       "      <td>-2.436490</td>\n",
       "      <td>3.316913</td>\n",
       "      <td>-0.608485</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.999081</td>\n",
       "      <td>75</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>0.151571</td>\n",
       "      <td>1331.073970</td>\n",
       "      <td>1973.643437</td>\n",
       "      <td>2900.174130</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>-221.802549</td>\n",
       "      <td>110.843070</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.037723</td>\n",
       "      <td>-12.652228</td>\n",
       "      <td>-1.821905</td>\n",
       "      <td>-7.260097</td>\n",
       "      <td>-6.660252</td>\n",
       "      <td>-14.682694</td>\n",
       "      <td>-11.719264</td>\n",
       "      <td>-11.025216</td>\n",
       "      <td>-13.387260</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.570312</td>\n",
       "      <td>91</td>\n",
       "      <td>0.269320</td>\n",
       "      <td>0.119072</td>\n",
       "      <td>1361.045467</td>\n",
       "      <td>1567.804596</td>\n",
       "      <td>2739.625101</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>-207.208080</td>\n",
       "      <td>132.799175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613248</td>\n",
       "      <td>0.384877</td>\n",
       "      <td>2.605128</td>\n",
       "      <td>-5.188924</td>\n",
       "      <td>-9.527455</td>\n",
       "      <td>-9.244394</td>\n",
       "      <td>-2.848274</td>\n",
       "      <td>-1.418707</td>\n",
       "      <td>-5.932607</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.499023</td>\n",
       "      <td>74</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.137728</td>\n",
       "      <td>1811.076084</td>\n",
       "      <td>2052.332563</td>\n",
       "      <td>3927.809582</td>\n",
       "      <td>0.075480</td>\n",
       "      <td>-145.434568</td>\n",
       "      <td>102.829023</td>\n",
       "      <td>...</td>\n",
       "      <td>7.457218</td>\n",
       "      <td>-10.470444</td>\n",
       "      <td>-2.360483</td>\n",
       "      <td>-6.783623</td>\n",
       "      <td>2.671134</td>\n",
       "      <td>-4.760879</td>\n",
       "      <td>-0.949005</td>\n",
       "      <td>0.024832</td>\n",
       "      <td>-2.005315</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tempo  beats  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  103.359375     50     0.380260  0.248262        2116.942959   \n",
       "1   95.703125     44     0.306451  0.113475        1156.070496   \n",
       "2  151.999081     75     0.253487  0.151571        1331.073970   \n",
       "3  184.570312     91     0.269320  0.119072        1361.045467   \n",
       "4  161.499023     74     0.391059  0.137728        1811.076084   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         1956.611056  4196.107960            0.127272  -26.929785   \n",
       "1         1497.668176  2170.053545            0.058613 -233.860772   \n",
       "2         1973.643437  2900.174130            0.042967 -221.802549   \n",
       "3         1567.804596  2739.625101            0.069124 -207.208080   \n",
       "4         2052.332563  3927.809582            0.075480 -145.434568   \n",
       "\n",
       "        mfcc2  ...     mfcc12     mfcc13    mfcc14    mfcc15    mfcc16  \\\n",
       "0  107.334008  ...  14.336612 -13.821769  7.562789 -6.181372  0.330165   \n",
       "1  136.170239  ...  -2.250578   3.959198  5.322555  0.812028 -1.107202   \n",
       "2  110.843070  ... -13.037723 -12.652228 -1.821905 -7.260097 -6.660252   \n",
       "3  132.799175  ...  -0.613248   0.384877  2.605128 -5.188924 -9.527455   \n",
       "4  102.829023  ...   7.457218 -10.470444 -2.360483 -6.783623  2.671134   \n",
       "\n",
       "      mfcc17     mfcc18     mfcc19     mfcc20  label  \n",
       "0  -6.829571   0.965922  -7.570825   2.918987  blues  \n",
       "1  -4.556555  -2.436490   3.316913  -0.608485  blues  \n",
       "2 -14.682694 -11.719264 -11.025216 -13.387260  blues  \n",
       "3  -9.244394  -2.848274  -1.418707  -5.932607  blues  \n",
       "4  -4.760879  -0.949005   0.024832  -2.005315  blues  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando la normalización de los datos\n",
    "Xinput, mediaXinput, stdXinput = normalize(Xinput)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Xinput.shape)\n",
    "print(genres.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folds cross validation\n",
    "### 2 capas intermedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aprendizaje: 0.2, épocas: 1000 Average acc: 0.26702750654846463\n",
      "Tasa de aprendizaje: 0.2, épocas: 1500 Average acc: 0.24694454933975893\n",
      "Tasa de aprendizaje: 0.2, épocas: 2000 Average acc: 0.3059976143808479\n",
      "Tasa de aprendizaje: 0.2, épocas: 2500 Average acc: 0.2560164955374536\n",
      "Tasa de aprendizaje: 0.2, épocas: 3000 Average acc: 0.25301648954343564\n",
      "Tasa de aprendizaje: 0.1, épocas: 1000 Average acc: 0.3280016543489597\n",
      "Tasa de aprendizaje: 0.1, épocas: 1500 Average acc: 0.34204264144383906\n",
      "Tasa de aprendizaje: 0.1, épocas: 2000 Average acc: 0.34893576210941485\n",
      "Tasa de aprendizaje: 0.1, épocas: 2500 Average acc: 0.36602171033308756\n",
      "Tasa de aprendizaje: 0.1, épocas: 3000 Average acc: 0.32398865931800064\n",
      "Tasa de aprendizaje: 0.07, épocas: 1000 Average acc: 0.3710087332841823\n",
      "Tasa de aprendizaje: 0.07, épocas: 1500 Average acc: 0.3819717921514329\n",
      "Tasa de aprendizaje: 0.07, épocas: 2000 Average acc: 0.384986783190376\n",
      "Tasa de aprendizaje: 0.07, épocas: 2500 Average acc: 0.36902771034507564\n",
      "Tasa de aprendizaje: 0.07, épocas: 3000 Average acc: 0.3810007612402822\n",
      "Tasa de aprendizaje: 0.05, épocas: 1000 Average acc: 0.4319948691206177\n",
      "Tasa de aprendizaje: 0.05, épocas: 1500 Average acc: 0.412010813208418\n",
      "Tasa de aprendizaje: 0.05, épocas: 2000 Average acc: 0.45497593401785025\n",
      "Tasa de aprendizaje: 0.05, épocas: 2500 Average acc: 0.4170338002673332\n",
      "Tasa de aprendizaje: 0.05, épocas: 3000 Average acc: 0.44697691703679726\n",
      "Results\n",
      "Best learning rate: 0.05\n",
      "Best Nro epochs: 2000\n",
      "Best Average Accuracy: 0.45497593401785025\n"
     ]
    }
   ],
   "source": [
    "myparams = {\n",
    "            'layers': [Xinput.shape[1],10,10,genres.shape[1]],\n",
    "            'epochs': [1000, 1500, 2000, 2500, 3000],\n",
    "            'learning': [0.2, 0.1, 0.07, 0.05]\n",
    "           }\n",
    "KfoldsCrossValidation(np.array(Xinput), np.array(Data['label']), np.array(genres), myparams, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 capas intermedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aprendizaje: 0.2, épocas: 1000 Average acc: 0.1289463115810421\n",
      "Tasa de aprendizaje: 0.2, épocas: 1500 Average acc: 0.10800620980261699\n",
      "Tasa de aprendizaje: 0.2, épocas: 2000 Average acc: 0.10099920279560998\n",
      "Tasa de aprendizaje: 0.2, épocas: 2500 Average acc: 0.14003824183464902\n",
      "Tasa de aprendizaje: 0.2, épocas: 3000 Average acc: 0.130936325547104\n",
      "Tasa de aprendizaje: 0.1, épocas: 1000 Average acc: 0.4450228671785558\n",
      "Tasa de aprendizaje: 0.1, épocas: 1500 Average acc: 0.4609789430148712\n",
      "Tasa de aprendizaje: 0.1, épocas: 2000 Average acc: 0.46699094303884725\n",
      "Tasa de aprendizaje: 0.1, épocas: 2500 Average acc: 0.44404284524045007\n",
      "Tasa de aprendizaje: 0.1, épocas: 3000 Average acc: 0.45800291309273344\n",
      "Tasa de aprendizaje: 0.07, épocas: 1000 Average acc: 0.43901086715457965\n",
      "Tasa de aprendizaje: 0.07, épocas: 1500 Average acc: 0.45898892904880934\n",
      "Tasa de aprendizaje: 0.07, épocas: 2000 Average acc: 0.4519789250328172\n",
      "Tasa de aprendizaje: 0.07, épocas: 2500 Average acc: 0.4579969190747634\n",
      "Tasa de aprendizaje: 0.07, épocas: 3000 Average acc: 0.48400496304687923\n",
      "Tasa de aprendizaje: 0.05, épocas: 1000 Average acc: 0.47397697098295904\n",
      "Tasa de aprendizaje: 0.05, épocas: 1500 Average acc: 0.5179790569012126\n",
      "Tasa de aprendizaje: 0.05, épocas: 2000 Average acc: 0.5089910269550989\n",
      "Tasa de aprendizaje: 0.05, épocas: 2500 Average acc: 0.5080080080080079\n",
      "Tasa de aprendizaje: 0.05, épocas: 3000 Average acc: 0.48898299497101894\n",
      "Results\n",
      "Best learning rate: 0.05\n",
      "Best Nro epochs: 1500\n",
      "Best Average Accuracy: 0.5179790569012126\n"
     ]
    }
   ],
   "source": [
    "myparams['layers'] = [Xinput.shape[1],10, 10, 10, genres.shape[1]]\n",
    "KfoldsCrossValidation(np.array(Xinput), np.array(Data['label']), np.array(genres), myparams, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 capas intermedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myparams['layers'] = [Xinput.shape[1], 10, 10, 10, 10, genres.shape[1]]\n",
    "KfoldsCrossValidation(np.array(Xinput), np.array(Data['label']), np.array(genres), myparams, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leo los datos\n",
    "TitanicData = pd.read_csv('titani.csv')\n",
    "TitanicData = TitanicData[['filename']], axis=1)\n",
    "# hacemos un shuffle de los datos\n",
    "# Data = Data.sample(frac=1).reset_index(drop=True)\n",
    "print(\"Music genres:\\n\", Data['label'].value_counts())\n",
    "Data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
